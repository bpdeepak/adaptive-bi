# adaptive-bi-system/.env
# Environment variables for your project services

# MongoDB Configuration (Phase 1)
MONGO_USERNAME=admin
MONGO_PASSWORD=admin123
MONGO_HOST=localhost # This is the service name in docker-compose.yml
MONGO_PORT=27017
MONGO_DB_NAME=adaptive_bi
MONGO_URI=mongodb://${MONGO_USERNAME}:${MONGO_PASSWORD}@${MONGO_HOST}:${MONGO_PORT}/${MONGO_DB_NAME}?authSource=admin

# Data Streaming Configuration
STREAM_INTERVAL_SECONDS=0.5 # Interval for data generation in streaming_etl.py
NUM_INITIAL_USERS=5000
NUM_INITIAL_PRODUCTS=1000
TRANSACTIONS_PER_SECOND=100
USER_ACTIVITIES_PER_SECOND=250
FEEDBACK_PER_MINUTE=15
NEW_USER_PROBABILITY_PER_BATCH=0.0005
NEW_PRODUCT_PROBABILITY_PER_BATCH=0.0002
INSERT_BATCH_SIZE=1000
REPORTING_INTERVAL_SECONDS=10

# Backend Configuration (Phase 2)
NODE_ENV=development
BACKEND_PORT=3000 # Your server.js uses BACKEND_PORT
MONGO_URI=mongodb://admin:admin123@mongodb:27017/adaptive_bi?authSource=admin

# JWT Secret for Authentication (IMPORTANT: CHANGE THIS FOR PRODUCTION!)
JWT_SECRET=a_very_secret_key_for_jwt_development_only_123456
JWT_EXPIRES_IN=1h

# Frontend URL (for CORS - as used in your server.js for Socket.IO)
FRONTEND_URL=http://localhost:5173 # Vite dev server runs on 5173


# AI Service Configuration (Phase 3)
AI_SERVICE_HOST=0.0.0.0
AI_SERVICE_PORT=8000
AI_SERVICE_DEBUG=True # Set to False for production

# MongoDB Connection for AI Service (should match backend's MONGO_URI, but relative to service)
MONGODB_URL=mongodb://admin:admin123@mongodb:27017/adaptive_bi?authSource=admin
DATABASE_NAME=adaptive_bi

# AI Model Specific Settings
# Model save path - use relative path for local development, Docker uses absolute path
MODEL_SAVE_PATH=models/saved_models

# NEW: Model retraining interval in MINUTES
MODEL_RETRAIN_INTERVAL_MINUTES=15 # Set to 0 to DISABLE, 1440 for daily (24 hours), 10080 for weekly
# OLD: RETRAIN_INTERVAL_HOURS=24 # This line will be ignored by new config.py, can be removed

# Forecasting Model Parameters
FORECAST_HORIZON=7 # Days to forecast (e.g., 7 days)
FORECAST_MODEL_TYPE=RandomForestRegressor # RandomForestRegressor or LinearRegression

# Anomaly Detection Model Parameters
ANOMALY_THRESHOLD=0.01 # Contamination for IsolationForest (e.g., 0.01 for 1% anomalies)
ANOMALY_MODEL_TYPE=IsolationForest # IsolationForest or OneClassSVM

# Recommendation Model Parameters
MIN_INTERACTIONS_FOR_RECOMMENDATION=5 # Minimum number of user interactions to be included in matrix
RECOMMENDER_MODEL_TYPE=SVD # SVD or KNNWithMeans (if implemented using Surprise, for example)

# Data Collection Window for ML model training (in days)
DATA_COLLECTION_DAYS=90

# CORS Settings for AI Service (allow specific origins or '*')
CORS_ORIGINS=* # For development, allows all. Restrict for production: http://localhost:3000,http://localhost:5173

# Phase 4: Advanced AI & Cognitive Reasoning Configuration
# BASE_MODEL_DIR is already defined as MODEL_SAVE_PATH
# LOG_LEVEL is usually handled by your existing logger config, but can be explicitly set
# LOG_LEVEL=INFO # Example: INFO, DEBUG, WARNING, ERROR

# Dynamic Pricing Model Configuration (Phase 4)
PRICING_TRAINING_DAYS=180 # Data window for training pricing model in days
PRICING_RETRAIN_INTERVAL_DAYS=30 # How often to retrain pricing model in days
MIN_PRICING_DATA_POINTS=1000 # Minimum data points required to train pricing model

# Churn Prediction Model Configuration (Phase 4)
CHURN_TRAINING_DAYS=365 # Data window for training churn model in days
CHURN_RETRAIN_INTERVAL_DAYS=60 # How often to retrain churn model in days
CHURN_BASELINE_RATE=0.1 # Baseline churn rate (e.g., 0.1 for 10%)
MIN_CHURN_DATA_POINTS=500 # Minimum data points required to train churn model

# Knowledge Graph Configuration (Phase 4)
KG_BUILD_INTERVAL_HOURS=1 # How often to rebuild the knowledge graph in hours
MIN_KG_TRANSACTIONS=100 # Minimum transactions required to build the knowledge graph

# Explainable AI Configuration (Phase 4)
SHAP_SAMPLE_SIZE=500 # Number of samples for SHAP global explanations
LIME_NUM_FEATURES=10 # Number of features to explain for LIME

# Celery and Redis Configuration (for background tasks like retraining)
# Ensure Redis service is running and accessible from your AI Service container
REDIS_HOST=redis # This is the service name if you use docker-compose
REDIS_PORT=6379
# Redis database index for Celery broker and backend
REDIS_DB=0

CELERY_BROKER_URL=redis://redis:6379/0 # Points to your Redis broker
CELERY_RESULT_BACKEND=redis://redis:6379/0 # Points to your Redis result backend